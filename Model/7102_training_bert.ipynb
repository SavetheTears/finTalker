{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "course_data = pd.read_csv('training_pd.csv')\n",
    "user_input = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_data['label'] = course_data['label'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_data['full_text'] = course_data['Job']+course_data['Course_Name']+course_data['Course_Hard_Skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Softskills</th>\n",
       "      <th>Hardskills</th>\n",
       "      <th>Course_Name</th>\n",
       "      <th>Course_Description</th>\n",
       "      <th>Course_Hard_Skills</th>\n",
       "      <th>Course_Soft_Skills</th>\n",
       "      <th>label</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mortgage Advisor</td>\n",
       "      <td>Communication skills, active listening, proble...</td>\n",
       "      <td>Knowledge of mortgage products and regulations...</td>\n",
       "      <td>Case studies in corporate finance</td>\n",
       "      <td>structured around the most important financial...</td>\n",
       "      <td>financial analysis, decision making, risk asse...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Mortgage AdvisorCase studies in corporate fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mortgage Advisor</td>\n",
       "      <td>Communication skills, active listening, proble...</td>\n",
       "      <td>Knowledge of mortgage products and regulations...</td>\n",
       "      <td>Behavioural and sociological finance</td>\n",
       "      <td>covers current developments in finance. Possib...</td>\n",
       "      <td>Understanding current developments in finance,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Mortgage AdvisorBehavioural and sociological f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mortgage Advisor</td>\n",
       "      <td>Communication skills, active listening, proble...</td>\n",
       "      <td>Knowledge of mortgage products and regulations...</td>\n",
       "      <td>Senior seminar in economics and finance</td>\n",
       "      <td>applies core theoretical knowledge in economic...</td>\n",
       "      <td>research skills, theoretical knowledge in econ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Mortgage AdvisorSenior seminar in economics an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mortgage Advisor</td>\n",
       "      <td>Communication skills, active listening, proble...</td>\n",
       "      <td>Knowledge of mortgage products and regulations...</td>\n",
       "      <td>Current issues in asset management and private...</td>\n",
       "      <td>seeks to cover current development and current...</td>\n",
       "      <td>Asset management, Private banking, Identifying...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Mortgage AdvisorCurrent issues in asset manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mortgage Advisor</td>\n",
       "      <td>Communication skills, active listening, proble...</td>\n",
       "      <td>Knowledge of mortgage products and regulations...</td>\n",
       "      <td>Valuation using financial statements</td>\n",
       "      <td>o introduce students to the concepts of financ...</td>\n",
       "      <td>Basic skills and techniques to analyze financi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Mortgage AdvisorValuation using financial stat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Job                                         Softskills  \\\n",
       "0  Mortgage Advisor  Communication skills, active listening, proble...   \n",
       "1  Mortgage Advisor  Communication skills, active listening, proble...   \n",
       "2  Mortgage Advisor  Communication skills, active listening, proble...   \n",
       "3  Mortgage Advisor  Communication skills, active listening, proble...   \n",
       "4  Mortgage Advisor  Communication skills, active listening, proble...   \n",
       "\n",
       "                                          Hardskills  \\\n",
       "0  Knowledge of mortgage products and regulations...   \n",
       "1  Knowledge of mortgage products and regulations...   \n",
       "2  Knowledge of mortgage products and regulations...   \n",
       "3  Knowledge of mortgage products and regulations...   \n",
       "4  Knowledge of mortgage products and regulations...   \n",
       "\n",
       "                                         Course_Name  \\\n",
       "0                  Case studies in corporate finance   \n",
       "1               Behavioural and sociological finance   \n",
       "2            Senior seminar in economics and finance   \n",
       "3  Current issues in asset management and private...   \n",
       "4               Valuation using financial statements   \n",
       "\n",
       "                                  Course_Description  \\\n",
       "0  structured around the most important financial...   \n",
       "1  covers current developments in finance. Possib...   \n",
       "2  applies core theoretical knowledge in economic...   \n",
       "3  seeks to cover current development and current...   \n",
       "4  o introduce students to the concepts of financ...   \n",
       "\n",
       "                                  Course_Hard_Skills Course_Soft_Skills  \\\n",
       "0  financial analysis, decision making, risk asse...                NaN   \n",
       "1  Understanding current developments in finance,...                NaN   \n",
       "2  research skills, theoretical knowledge in econ...                NaN   \n",
       "3  Asset management, Private banking, Identifying...                NaN   \n",
       "4  Basic skills and techniques to analyze financi...                NaN   \n",
       "\n",
       "   label                                          full_text  \n",
       "0      1  Mortgage AdvisorCase studies in corporate fina...  \n",
       "1      1  Mortgage AdvisorBehavioural and sociological f...  \n",
       "2      1  Mortgage AdvisorSenior seminar in economics an...  \n",
       "3      1  Mortgage AdvisorCurrent issues in asset manage...  \n",
       "4      1  Mortgage AdvisorValuation using financial stat...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from collections import defaultdict\n",
    "dataset = defaultdict(dict)\n",
    "train = dict()\n",
    "val = dict()\n",
    "train['text'] = list(course_data['full_text'][:100])\n",
    "val['text'] = list(course_data['full_text'][100:])\n",
    "train['label'] = list(course_data['label'][:100])\n",
    "val['label'] = list(course_data['label'][100:])\n",
    "dataset['train'] = train\n",
    "dataset['val'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 14344,  8619, 18382,  2913,  1999,  5971,  5446, 16294,  2319,\n",
       "          13247,  4106,  1010,  3247,  2437,  1010,  3891,  7667,  1010,  3007,\n",
       "           3252,  4106,  1010,  5211, 26004,  1010, 10067,  3006,  4106,  1010,\n",
       "           5971, 10615,  4106,  1010,  5356,  4834,  2968,  1998,  4106,  1010,\n",
       "           1049,  1004,  1037,  4106,  1012,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [  101, 14344,  8619,  4783,  3270, 25500, 11137,  1998, 24846,  5446,\n",
       "          20824, 24911,  2783,  8973,  1999,  5446,  1010,  3716,  1997,  3036,\n",
       "           6202,  1998,  3006,  2437,  1010,  4824,  6957,  4106,  1998,  3361,\n",
       "          21012,  1010,  3716,  1997,  5211,  9942,  2005,  2334,  6089,  1010,\n",
       "           3754,  2000, 17908,  1998,  6848,  2783,  3314,  1999,  5446,  1012,\n",
       "            102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0]]),\n",
       " 'label': tensor([1, 1])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(dataset['train']['text'], truncation=True, padding=True)\n",
    "val_encodings = tokenizer(dataset['val']['text'], truncation=True, padding=True)\n",
    "class tokenized_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "    def __getitem__(self, idx):\n",
    "        item = {'input_ids': torch.tensor(self.data['input_ids'][idx]),\n",
    "                'attention_mask': torch.tensor(self.data['attention_mask'][idx])}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "small_tokenized_dataset = defaultdict()\n",
    "small_tokenized_dataset['train']=tokenized_dataset(train_encodings,list(dataset['train']['label']))\n",
    "small_tokenized_dataset['val'] =tokenized_dataset(val_encodings,list(dataset['val']['label']))\n",
    "\n",
    "small_tokenized_dataset['train'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8db000960a4f008ac95b1b4f83331e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train acc = 0.5900, validation acc = 0.6809\n",
      "Epoch 2: train acc = 0.6000, validation acc = 0.6809\n",
      "Epoch 3: train acc = 0.6400, validation acc = 0.8319\n",
      "Epoch 4: train acc = 0.9000, validation acc = 0.8702\n",
      "Epoch 5: train acc = 0.9600, validation acc = 0.8936\n",
      "Epoch 6: train acc = 0.9800, validation acc = 0.8787\n",
      "Epoch 7: train acc = 1.0000, validation acc = 0.9000\n",
      "Epoch 8: train acc = 1.0000, validation acc = 0.9170\n",
      "distilbert training time used: 7\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm\n",
    "import os \n",
    "from transformers import DistilBertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "# 设置随机数种子\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Write your code here\n",
    "import datetime\n",
    "train_data_loader = DataLoader(small_tokenized_dataset['train'],batch_size=12,shuffle=True)\n",
    "val_data_loader = DataLoader(small_tokenized_dataset['val'],batch_size=12)\n",
    "# Define your model. optimizer, hyper-parameter and etc.\n",
    "from sklearn.metrics import accuracy_score\n",
    "distil_bert_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=1,problem_type=\"binary_label_classification\")\n",
    "optimizer = AdamW(distil_bert_model.parameters(),betas=(0.9,0.999),lr=5e-5,eps=1e-5,weight_decay=1e-3)\n",
    "num_epochs = 8\n",
    "distil_bert_model.cuda()\n",
    "bceloss = torch.nn.BCELoss()\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=3, num_training_steps=num_epochs)\n",
    "start_time = datetime.datetime.now()\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    #train and evaluate your model\n",
    "    # training\n",
    "    distil_bert_model.train()\n",
    "    train_y_pred = []\n",
    "    train_y_true = []\n",
    "    for step, batch in enumerate(train_data_loader):\n",
    "        input_ids = batch['input_ids'].cuda()\n",
    "        attention_mask = batch['attention_mask'].cuda()\n",
    "        labels = batch['label'].cuda()\n",
    "        y_pred = distil_bert_model(input_ids,attention_mask=attention_mask, labels=labels)\n",
    "        y_pred = torch.sigmoid(y_pred.logits).squeeze().float()\n",
    "        loss = bceloss(y_pred, labels.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_y_pred.extend((y_pred>0.5).tolist())\n",
    "        train_y_true.extend(batch['label'].tolist())\n",
    "    train_acc = accuracy_score(train_y_pred, train_y_true)\n",
    "    # evaluation\n",
    "    distil_bert_model.eval()\n",
    "    val_y_pred = []\n",
    "    val_y_true = []\n",
    "    for step, batch in enumerate(val_data_loader):\n",
    "        input_ids = batch['input_ids'].cuda()\n",
    "        attention_mask = batch['attention_mask'].cuda()\n",
    "        labels = batch['label'].cuda()\n",
    "        y_pred = distil_bert_model(input_ids,attention_mask=attention_mask, labels=labels)\n",
    "        y_pred = torch.sigmoid(y_pred.logits).squeeze().float()\n",
    "        val_y_pred.extend((y_pred>0.5).tolist())\n",
    "        val_y_true.extend(batch['label'].tolist())\n",
    "    validation_acc = accuracy_score(val_y_pred, val_y_true)\n",
    "    scheduler.step()\n",
    "    # print the training process\n",
    "    print(\"Epoch {}: train acc = {:.4f}, validation acc = {:.4f}\".format(epoch + 1, train_acc, validation_acc))\n",
    "end_time = datetime.datetime.now()\n",
    "print('distilbert training time used:',(end_time-start_time).seconds)\n",
    "torch.save(distil_bert_model.state_dict(),'pytorch_model.pth')\n",
    "# ------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = pd.read_csv('output_cleaned.csv')\n",
    "course_skill_dict = courses[['Course_Name','Course_Hard_Skills']].set_index('Course_Name').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = []\n",
    "user_input = 'economist'\n",
    "courses.dropna(subset=['Course_Hard_Skills'],inplace=True,axis=0)\n",
    "courses = courses.reset_index(drop=True)\n",
    "for i in range(courses.shape[0]):\n",
    "    \n",
    "    input_joined = user_input+' '.join(list(courses.loc[i,['Course_Name','Course_Hard_Skills']]))\n",
    "    #print(input_joined)\n",
    "    inference.append(input_joined)\n",
    "#4\n",
    "import numpy as np\n",
    "inference = tokenizer(inference,padding=True,truncation=True)\n",
    "inference = tokenized_dataset(inference,label=np.ones(len(inference['input_ids'])))\n",
    "infer_loader = DataLoader(inference,batch_size=24,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skill learned: Investment consulting industry, Asset management, Private wealth industry, Institutional investors, Family office, Practical understanding, Industry relevance.\n",
      "\n",
      "courses recommended:\n",
      "0 , Investment consulting, institutional business and family office\n",
      "1 , Project management\n",
      "2 , Current issues in asset management and private banking industr\n",
      "3 , Behavioural and sociological finance\n",
      "4 , Risk management\n",
      "5 , Valuation using financial statements\n",
      "6 , The political economy of globalization\n",
      "7 , Private banking and wealth management\n",
      "8 , Senior seminar in economics and finance\n",
      "9 , Management control\n"
     ]
    }
   ],
   "source": [
    "inf_y_pred = []\n",
    "distil_bert_model.eval()\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(infer_loader):\n",
    "            input_ids = batch['input_ids'].cuda()\n",
    "            attention_mask = batch['attention_mask'].cuda()\n",
    "            y_pred = distil_bert_model(input_ids,attention_mask=attention_mask)\n",
    "            inf_y_pred.extend(torch.sigmoid(y_pred.logits[:,0]).tolist())\n",
    "_,index = torch.topk(torch.tensor(inf_y_pred),10)\n",
    "course_name = courses.loc[index,'Course_Name'].values\n",
    "skills = []\n",
    "for c in course_name:\n",
    "    skills.append(course_skill_dict['Course_Hard_Skills'][c])\n",
    "print('skill learned:',skills[0])\n",
    "print()\n",
    "print('courses recommended:')\n",
    "for i,c in enumerate(course_name):\n",
    "    print(i,',',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KD_training",
   "language": "python",
   "name": "kd_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
